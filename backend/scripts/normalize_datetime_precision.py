#!/usr/bin/env python3
"""
æ—¶é—´ç²¾åº¦æ ‡å‡†åŒ–è„šæœ¬

å°†ç³»ç»Ÿä¸­æ‰€æœ‰æ—¶é—´å­—æ®µç»Ÿä¸€ä¸ºç§’çº§ç²¾åº¦ï¼Œç§»é™¤ä¸å¿…è¦çš„å¾®ç§’ç²¾åº¦ã€‚
è¿™æ ·å¯ä»¥ï¼š
1. å‡å°‘å­˜å‚¨ç©ºé—´
2. æé«˜æŸ¥è¯¢æ€§èƒ½  
3. ç®€åŒ–æ—¶é—´æ¯”è¾ƒé€»è¾‘
4. ç»Ÿä¸€æ—¶é—´æ˜¾ç¤ºæ ¼å¼
"""

import asyncio
import sys
import os
from datetime import datetime, timezone
from sqlalchemy import text, select, func
from sqlalchemy.ext.asyncio import AsyncSession

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from app.core.database import get_db, async_engine
from app.models.user import User
from app.models.activity import Activity
from app.models.company import Company
from app.models.department import Department
from app.models.role import Role
from app.models.notification import Notification
from app.models.reward import Reward
from app.models.scoring import ScoringFactor, ScoreEntry, PointTransaction, PointDispute, PointPurchase


class DateTimePrecisionNormalizer:
    """æ—¶é—´ç²¾åº¦æ ‡å‡†åŒ–å™¨"""
    
    def __init__(self):
        self.tables_to_normalize = [
            # è¡¨å, æ—¶é—´å­—æ®µåˆ—è¡¨
            ('users', ['created_at', 'updated_at']),
            ('activities', ['created_at', 'completed_at', 'updated_at']),
            ('companies', ['created_at', 'updated_at']),
            ('departments', ['created_at', 'updated_at']),
            ('roles', ['created_at', 'updated_at']),
            ('notifications', ['created_at', 'read_at']),
            ('rewards', ['created_at', 'updated_at']),
            ('scoring_factors', ['created_at', 'updated_at']),
            ('score_entries', ['created_at']),
            ('point_transactions', ['created_at', 'dispute_deadline']),
            ('point_disputes', ['created_at', 'resolved_at']),
            ('point_purchases', ['created_at', 'updated_at']),
            ('pull_request_results', ['updated_at']),

        ]
    
    async def analyze_precision_usage(self, db: AsyncSession):
        """åˆ†æå½“å‰æ•°æ®åº“ä¸­æ—¶é—´ç²¾åº¦çš„ä½¿ç”¨æƒ…å†µ"""
        print("ğŸ” åˆ†ææ—¶é—´ç²¾åº¦ä½¿ç”¨æƒ…å†µ...")

        # æ£€æµ‹æ•°æ®åº“ç±»å‹
        dialect_name = db.bind.dialect.name
        print(f"ğŸ” æ£€æµ‹åˆ°æ•°æ®åº“ç±»å‹: {dialect_name}")

        total_records = 0
        microsecond_records = 0

        for table_name, datetime_columns in self.tables_to_normalize:
            try:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                if dialect_name == 'sqlite':
                    table_exists_query = f"""
                        SELECT COUNT(*) FROM sqlite_master
                        WHERE type='table' AND name='{table_name}'
                    """
                else:
                    table_exists_query = f"""
                        SELECT COUNT(*) FROM information_schema.tables
                        WHERE table_name = '{table_name}'
                    """

                result = await db.execute(text(table_exists_query))
                if result.scalar() == 0:
                    print(f"âš ï¸  è¡¨ {table_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    continue

                for column in datetime_columns:
                    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                    if dialect_name == 'sqlite':
                        # SQLite ä½¿ç”¨ PRAGMA table_info
                        col_result = await db.execute(text(f"PRAGMA table_info({table_name})"))
                        columns_info = col_result.fetchall()
                        column_exists = any(col[1] == column for col in columns_info)
                    else:
                        col_result = await db.execute(text(f"""
                            SELECT COUNT(*) FROM information_schema.columns
                            WHERE table_name = '{table_name}' AND column_name = '{column}'
                        """))
                        column_exists = col_result.scalar() > 0

                    if not column_exists:
                        print(f"âš ï¸  åˆ— {table_name}.{column} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                        continue

                    # ç»Ÿè®¡æ€»è®°å½•æ•°
                    total_result = await db.execute(text(f"""
                        SELECT COUNT(*) FROM {table_name}
                        WHERE {column} IS NOT NULL
                    """))
                    table_total = total_result.scalar() or 0
                    total_records += table_total

                    # ç»Ÿè®¡åŒ…å«å¾®ç§’çš„è®°å½•æ•°ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                    if dialect_name == 'sqlite':
                        # SQLite æ£€æŸ¥æ˜¯å¦åŒ…å«å°æ•°ç‚¹ï¼ˆç®€åŒ–æ£€æµ‹ï¼‰
                        microsecond_result = await db.execute(text(f"""
                            SELECT COUNT(*) FROM {table_name}
                            WHERE {column} IS NOT NULL
                            AND {column} LIKE '%.%'
                        """))
                    else:
                        microsecond_result = await db.execute(text(f"""
                            SELECT COUNT(*) FROM {table_name}
                            WHERE {column} IS NOT NULL
                            AND EXTRACT(microseconds FROM {column}) > 0
                        """))

                    table_microseconds = microsecond_result.scalar() or 0
                    microsecond_records += table_microseconds

                    if table_total > 0:
                        percentage = (table_microseconds / table_total) * 100
                        print(f"ğŸ“Š {table_name}.{column}: {table_microseconds}/{table_total} ({percentage:.1f}%) åŒ…å«å¾®ç§’")

            except Exception as e:
                print(f"âŒ åˆ†æè¡¨ {table_name} æ—¶å‡ºé”™: {e}")

        if total_records > 0:
            overall_percentage = (microsecond_records / total_records) * 100
            print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡: {microsecond_records}/{total_records} ({overall_percentage:.1f}%) è®°å½•åŒ…å«å¾®ç§’ç²¾åº¦")
            print(f"ğŸ’¾ é¢„è®¡èŠ‚çœå­˜å‚¨ç©ºé—´: ~{microsecond_records * 4} å­—èŠ‚ (æ¯ä¸ªå¾®ç§’å­—æ®µ4å­—èŠ‚)")

        return total_records, microsecond_records
    
    async def normalize_table_precision(self, db: AsyncSession, table_name: str, datetime_columns: list):
        """æ ‡å‡†åŒ–å•ä¸ªè¡¨çš„æ—¶é—´ç²¾åº¦"""
        try:
            # æ£€æµ‹æ•°æ®åº“ç±»å‹
            dialect_name = db.bind.dialect.name

            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
            if dialect_name == 'sqlite':
                table_exists_query = f"""
                    SELECT COUNT(*) FROM sqlite_master
                    WHERE type='table' AND name='{table_name}'
                """
            else:
                table_exists_query = f"""
                    SELECT COUNT(*) FROM information_schema.tables
                    WHERE table_name = '{table_name}'
                """

            result = await db.execute(text(table_exists_query))
            if result.scalar() == 0:
                print(f"âš ï¸  è¡¨ {table_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                return 0

            updated_count = 0

            for column in datetime_columns:
                # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                if dialect_name == 'sqlite':
                    # SQLite ä½¿ç”¨ PRAGMA table_info
                    col_result = await db.execute(text(f"PRAGMA table_info({table_name})"))
                    columns_info = col_result.fetchall()
                    column_exists = any(col[1] == column for col in columns_info)
                else:
                    col_result = await db.execute(text(f"""
                        SELECT COUNT(*) FROM information_schema.columns
                        WHERE table_name = '{table_name}' AND column_name = '{column}'
                    """))
                    column_exists = col_result.scalar() > 0

                if not column_exists:
                    print(f"âš ï¸  åˆ— {table_name}.{column} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    continue

                # æ›´æ–°æ—¶é—´ç²¾åº¦ï¼šç§»é™¤å¾®ç§’éƒ¨åˆ†ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                if dialect_name == 'sqlite':
                    # SQLite: ä½¿ç”¨ datetime() å‡½æ•°ç§»é™¤å¾®ç§’
                    # å…ˆè·å–åŒ…å«å¾®ç§’çš„è®°å½•æ•°
                    count_result = await db.execute(text(f"""
                        SELECT COUNT(*) FROM {table_name}
                        WHERE {column} IS NOT NULL
                        AND {column} LIKE '%.%'
                    """))
                    records_to_update = count_result.scalar() or 0

                    if records_to_update > 0:
                        # ä½¿ç”¨ SQLite çš„ datetime() å‡½æ•°æ ‡å‡†åŒ–æ—¶é—´
                        result = await db.execute(text(f"""
                            UPDATE {table_name}
                            SET {column} = datetime(substr({column}, 1, 19))
                            WHERE {column} IS NOT NULL
                            AND {column} LIKE '%.%'
                        """))
                        column_updated = result.rowcount
                    else:
                        column_updated = 0
                else:
                    # PostgreSQL: ä½¿ç”¨ date_trunc
                    result = await db.execute(text(f"""
                        UPDATE {table_name}
                        SET {column} = date_trunc('second', {column})
                        WHERE {column} IS NOT NULL
                        AND EXTRACT(microseconds FROM {column}) > 0
                    """))
                    column_updated = result.rowcount

                updated_count += column_updated

                if column_updated > 0:
                    print(f"âœ… {table_name}.{column}: æ ‡å‡†åŒ–äº† {column_updated} æ¡è®°å½•")

            return updated_count

        except Exception as e:
            print(f"âŒ æ ‡å‡†åŒ–è¡¨ {table_name} æ—¶å‡ºé”™: {e}")
            return 0
    
    async def normalize_all_tables(self, db: AsyncSession):
        """æ ‡å‡†åŒ–æ‰€æœ‰è¡¨çš„æ—¶é—´ç²¾åº¦"""
        print("ğŸ”§ å¼€å§‹æ ‡å‡†åŒ–æ—¶é—´ç²¾åº¦...")
        
        total_updated = 0
        
        for table_name, datetime_columns in self.tables_to_normalize:
            updated = await self.normalize_table_precision(db, table_name, datetime_columns)
            total_updated += updated
        
        await db.commit()
        print(f"\nğŸ‰ æ ‡å‡†åŒ–å®Œæˆï¼æ€»å…±æ›´æ–°äº† {total_updated} æ¡è®°å½•")
        return total_updated
    
    async def verify_normalization(self, db: AsyncSession):
        """éªŒè¯æ ‡å‡†åŒ–ç»“æœ"""
        print("ğŸ” éªŒè¯æ ‡å‡†åŒ–ç»“æœ...")

        # æ£€æµ‹æ•°æ®åº“ç±»å‹
        dialect_name = db.bind.dialect.name

        remaining_microseconds = 0

        for table_name, datetime_columns in self.tables_to_normalize:
            try:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                if dialect_name == 'sqlite':
                    table_exists_query = f"""
                        SELECT COUNT(*) FROM sqlite_master
                        WHERE type='table' AND name='{table_name}'
                    """
                else:
                    table_exists_query = f"""
                        SELECT COUNT(*) FROM information_schema.tables
                        WHERE table_name = '{table_name}'
                    """

                result = await db.execute(text(table_exists_query))
                if result.scalar() == 0:
                    continue

                for column in datetime_columns:
                    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                    if dialect_name == 'sqlite':
                        # SQLite ä½¿ç”¨ PRAGMA table_info
                        col_result = await db.execute(text(f"PRAGMA table_info({table_name})"))
                        columns_info = col_result.fetchall()
                        column_exists = any(col[1] == column for col in columns_info)
                    else:
                        col_result = await db.execute(text(f"""
                            SELECT COUNT(*) FROM information_schema.columns
                            WHERE table_name = '{table_name}' AND column_name = '{column}'
                        """))
                        column_exists = col_result.scalar() > 0

                    if not column_exists:
                        continue

                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾®ç§’ç²¾åº¦çš„è®°å½•ï¼ˆå…¼å®¹ä¸åŒæ•°æ®åº“ï¼‰
                    if dialect_name == 'sqlite':
                        # SQLite æ£€æŸ¥æ˜¯å¦åŒ…å«å°æ•°ç‚¹
                        microsecond_result = await db.execute(text(f"""
                            SELECT COUNT(*) FROM {table_name}
                            WHERE {column} IS NOT NULL
                            AND {column} LIKE '%.%'
                        """))
                    else:
                        microsecond_result = await db.execute(text(f"""
                            SELECT COUNT(*) FROM {table_name}
                            WHERE {column} IS NOT NULL
                            AND EXTRACT(microseconds FROM {column}) > 0
                        """))

                    remaining = microsecond_result.scalar() or 0
                    remaining_microseconds += remaining

                    if remaining > 0:
                        print(f"âš ï¸  {table_name}.{column}: ä»æœ‰ {remaining} æ¡è®°å½•åŒ…å«å¾®ç§’")

            except Exception as e:
                print(f"âŒ éªŒè¯è¡¨ {table_name} æ—¶å‡ºé”™: {e}")

        if remaining_microseconds == 0:
            print("âœ… éªŒè¯é€šè¿‡ï¼æ‰€æœ‰æ—¶é—´å­—æ®µå·²æ ‡å‡†åŒ–ä¸ºç§’çº§ç²¾åº¦")
        else:
            print(f"âš ï¸  ä»æœ‰ {remaining_microseconds} æ¡è®°å½•åŒ…å«å¾®ç§’ç²¾åº¦")

        return remaining_microseconds == 0


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ—¶é—´ç²¾åº¦æ ‡å‡†åŒ–è„šæœ¬å¯åŠ¨")
    print("=" * 50)
    
    normalizer = DateTimePrecisionNormalizer()
    
    async with async_engine.begin() as conn:
        db = AsyncSession(bind=conn)
        
        try:
            # 1. åˆ†æå½“å‰ç²¾åº¦ä½¿ç”¨æƒ…å†µ
            total_records, microsecond_records = await normalizer.analyze_precision_usage(db)
            
            if microsecond_records == 0:
                print("âœ… æ‰€æœ‰æ—¶é—´å­—æ®µå·²ç»æ˜¯ç§’çº§ç²¾åº¦ï¼Œæ— éœ€å¤„ç†")
                return
            
            # 2. ç¡®è®¤æ˜¯å¦ç»§ç»­
            print(f"\nğŸ“‹ å°†è¦æ ‡å‡†åŒ– {microsecond_records} æ¡åŒ…å«å¾®ç§’ç²¾åº¦çš„è®°å½•")
            confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
            if confirm != 'y':
                print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return
            
            # 3. æ‰§è¡Œæ ‡å‡†åŒ–
            updated_count = await normalizer.normalize_all_tables(db)
            
            # 4. éªŒè¯ç»“æœ
            success = await normalizer.verify_normalization(db)
            
            if success:
                print("\nğŸ‰ æ—¶é—´ç²¾åº¦æ ‡å‡†åŒ–æˆåŠŸå®Œæˆï¼")
                print("ğŸ’¡ å»ºè®®ï¼šæ›´æ–°æ¨¡å‹å®šä¹‰ä»¥ä½¿ç”¨ç»Ÿä¸€çš„ç§’çº§ç²¾åº¦")
            else:
                print("\nâš ï¸  æ ‡å‡†åŒ–å¯èƒ½æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        
        except Exception as e:
            await db.rollback()
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
        
        finally:
            await db.close()


if __name__ == "__main__":
    asyncio.run(main())
